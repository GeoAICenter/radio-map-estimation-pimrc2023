{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is recommended to run this notebook with GPU support. If you have an Nvidea graphics card and drivers installed, the following block of code should show the details of the installed GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Untar Testing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code block below, specify the path to the saved testing data in tar format. This will untar the data into a folder of the same name in the parent directory of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUF595UIxGlm"
      },
      "outputs": [],
      "source": [
        "!tar -xkf '/path/to/saved/tar/file' -C '/path/to/save/untarred/files'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import model architectures and data structures\n",
        "\n",
        "os.chdir('path/to/repository')\n",
        "from test_utils import get_model_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed, define device\n",
        "\n",
        "seed = 3\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set batch size\n",
        "test_batch_size = 1024\n",
        "\n",
        "# Manually set values for buildings, unsampled locations, and sampled locations in the environment mask. \n",
        "# For the models in the PIMRC paper, these are set to \"None\", meaning they keep the default values of -1, 0, and 1 respectively.\n",
        "building_value = None\n",
        "unsampled_value = None\n",
        "sampled_value = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the folder to load trained models from. All models in the selected model_folder will be tested. Additionally create and specify a folder to save the results to, and specify the paths to the saved data and data scaler (located within this repository)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1ax78Ucwaa8"
      },
      "outputs": [],
      "source": [
        "# Set folder to load model(s) to test\n",
        "model_folder = '/folder/with/trained/models'\n",
        "\n",
        "# Set folder of results to save current results\n",
        "results_folder = '/folder/to/save/results'\n",
        "\n",
        "# Specify path to test data\n",
        "test_data_folder = '/path/to/saved/testing/data'\n",
        "\n",
        "# Specify path to data scaler\n",
        "scaler_path = 'scalers/minmax_scaler_zero_min134.joblib'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w21gqRPMvVkw"
      },
      "outputs": [],
      "source": [
        "model_names = glob.glob(os.path.join(model_folder, '*.pth'))\n",
        "for model_path in model_names:\n",
        "  error = get_model_error(model_path, scaler_path, building_value=building_value, sampled_value=sampled_value)\n",
        "  filename = os.path.basename(model_path).split('.')[0] + '.pickle'\n",
        "  with open(os.path.join(results_folder, filename), 'wb') as f:\n",
        "    pickle.dump(error, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
